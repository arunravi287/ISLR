### Chapter 6 - Linear Model Selection and Regularization

The linear model can be extended to give better prediction accuracy. This can be done by either reducing the number of predictors (using subset selection or dimensionality reduction) or constraining the linear coefficients (using regularization). This chapter explores the following major topics:
1. Best Subset Selection
2. Forward Subset Selection
3. Backward Subset Selection
4. Ridge Regression
5. Lasso Regression
6. Principal Component Analysis
7. Principal Component Regression
8. Partial Least Squares
9. Problems with High Dimensions


Link to Lab:
 - [Subset Selection Methods](https://github.com/arunravi287/ISLR/blob/main/Chapter%206/Labs/Subset%20Selection%20Methods.ipynb)
 - [Ridge Regression and the Lasso](https://github.com/arunravi287/ISLR/blob/main/Chapter%206/Labs/Ridge%20Regression%20and%20the%20Lasso.ipynb)
 - [PCR and PLS Regression](https://github.com/arunravi287/ISLR/blob/main/Chapter%206/Labs/PCR%20and%20PLS%20Regression.ipynb)

Links to Exercises:
 - [Conceptual Exercises]
 - [Applied Exercises]
