### Chapter 9 - Support Vector Machines

SVMs can efficiently perform a non-linear classification by implicitly mapping their inputs into high-dimensional feature spaces. A SVM constructs a hyperplane in a multi-dimensional space. A good separation is achieved by the hyperplane that has the largest distance to the nearest training-data point of any class (margin), since in general the larger the margin, the lower the generalization error of the classifier.This chapter explores the following major topics:
1. Hyperplanes
2. Maximal Margin Classifier
3. Support Vector Classifier
4. Support Vector Machines
5. Linear, Polynomial and Radial Kernels
6. Multiclass SVM
7. SVM vs Logistic Regression

Link to Lab:
 - [Support Vector Machines](https://github.com/arunravi287/ISLR/blob/main/Chapter%209/Labs/Support%20Vector%20Machines.ipynb)

Links to Exercises:
 - [Conceptual Exercises](https://arunravi287.github.io/ISLR/Chapter%209/Exercises/Conceptual%20Exercises/Conceptual%20Exercises.pdf)
 - [Applied Exercises](https://github.com/arunravi287/ISLR/blob/main/Chapter%209/Exercises/Applied%20Exercises.ipynb)
